version: "3.9"

services:
  # ============================
  # TTS Model Service (replicas)
  # ============================
  tts-api:
    image: 074697765782.dkr.ecr.us-east-1.amazonaws.com/tts:latest
    environment:
      - NVIDIA_VISIBLE_DEVICES=all    # Give container access to all GPUs
    networks:
      - ttsnet
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # Note: No "ports" â†’ replicas stay private (only NGINX talks to them)

  # ============================
  # NGINX Load Balancer
  # ============================
  nginx:
    image: nginx:stable
    container_name: nginx_lb
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro   # Use our config
    ports:
      - "8080:8080"   # Public REST endpoint
      - "5001:5001"   # Public gRPC endpoint
    depends_on:
      - tts-api
    networks:
      - ttsnet
    restart: unless-stopped

networks:
  ttsnet:
    driver: bridge
